{
	"PyNPEval/0": {
		"query": "Give me the code to check the inference latency benchmark of custom tflite model on rzv2m.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/1": {
		"query": "How to check the inference latency with my custom model on device?",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/2": {
		"query": "Show me an example to train for image classification task. Project name is 'my_proj'.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/3": {
		"query": "How can I get the information about compression?",
		"retrieved_APIs": {
			"API_1": "Compressor.get_compression(compression_id: str): Get information about a compression. Returns the information about the compression.\n\n\nParameters\n----------\ncompression_id (str): The ID of the compression.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_info = compressor.get_compression(compression_id='YOUR_COMPRESSION_ID')",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/4": {
		"query": "Show me an example to train ViT for image classification task. Train epoch has to be 100.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/5": {
		"query": "How can I benchmark a model?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/6": {
		"query": "How can I compress a model?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/7": {
		"query": "How to check the latency of my onnx model on the device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize the Trainer.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/8": {
		"query": "Can you provide an example of how to use the convert function?",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/9": {
		"query": "Train model for image classification.",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/10": {
		"query": "How to convert pytorch model to onnx?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/11": {
		"query": "Prune model automatically.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/12": {
		"query": "How can I benchmark a model on a device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/13": {
		"query": "How to convert onnx model to tensorrt model?",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/14": {
		"query": "Give me a code snippet to train a model.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/15": {
		"query": "Show me a code snippet to set a compression method.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/16": {
		"query": "How to convert yolox onnx model.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/17": {
		"query": "How can I set the output directory?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/18": {
		"query": "I want to convert model to tflite.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/19": {
		"query": "How to set the environment configuration with 42?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/20": {
		"query": "How to save the result?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/21": {
		"query": "I'd like to know how to set the compression method.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/22": {
		"query": "Give me a code snippet to train a model for the image segmentation task.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/23": {
		"query": "Can you set the augmentation configs?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/24": {
		"query": "I want to know how to compress my custom onnx model. Output_dir is './logs' and input shape is [1, 3, 224, 224].",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/25": {
		"query": "I have a model and target framework is tflite. And target device is raspberry pi 4b.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/26": {
		"query": "How to check the latency of my model on the device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize the Trainer.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/27": {
		"query": "How much memory is consumed to run the model with benchmark? Model path is 'yolox.tflite' and data type is fp16",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/28": {
		"query": "Give me the code to check the inference latency benchmark of custom model.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/29": {
		"query": "How to set batch size and use optimizer?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/30": {
		"query": "I want to know how to compress my custom model with singular value decomposition method.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/31": {
		"query": "Give me the code to check the inference latency benchmark.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/32": {
		"query": "How to benchmark custom tensorflow model?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
			"API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/33": {
		"query": "Show me how to initialize instance.",
		"retrieved_APIs": {
			"API_1": "NetsPresso.compressor(): Initialize and return a Compressor instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
			"API_2": "Compressor(token_handler: TokenHandler): Initialize the Compressor.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/34": {
		"query": "Code snippet to train MobileViT.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/35": {
		"query": "Give me the code snippet to set method to linear scaling.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/36": {
		"query": "Can you provide an example of how to set the logging?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/37": {
		"query": "Prune the model with L2 norm.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/38": {
		"query": "Convert my onnx model to tensorrt model.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/39": {
		"query": "Show me a code snippet to set a compression method to pruning.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/40": {
		"query": "How can I benchmark a device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/41": {
		"query": "How to set fx model?",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/42": {
		"query": "How to set augmentation config?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/43": {
		"query": "How to set the dataset?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/44": {
		"query": "How to convert pytorch model?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/45": {
		"query": "How to benchmark on device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
			"API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/46": {
		"query": "How to use Adagrad optimizer?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/47": {
		"query": "How can I benchmark a model on a Jetson-Nano device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/48": {
		"query": "I want to benchmark my model on device.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/49": {
		"query": "Provide an example of how to convert model.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/50": {
		"query": "How to benchmark custom model?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
			"API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/51": {
		"query": "I want to use optimizer and scheduler.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/52": {
		"query": "Can you provide an example of how to use the Converter.convert_model() function?",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/53": {
		"query": "I want to know how to compress my custom model with singular value decomposition method. Model path is 'my_model.onnx'.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/54": {
		"query": "Can you provide an example of how to set the configuration?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/55": {
		"query": "Prune the model with compression ratio 0.3.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/56": {
		"query": "Can you provide the code snippet for pruning?",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/57": {
		"query": "How to train SegFormer?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/58": {
		"query": "How to benchmark on raspberry pi 4b device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
			"API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/59": {
		"query": "Code snippet to prune the trained model.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/60": {
		"query": "I want to benchmark my model with int8.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/61": {
		"query": "Can you provide an example of how to convert a model?",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/62": {
		"query": "Give me a code snippet for image classification.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/63": {
		"query": "What is the input shape of the model?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/64": {
		"query": "Train yolox model.",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/65": {
		"query": "Can you convert model to the other framework?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/66": {
		"query": "Code snippet to convert to tflite model.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/67": {
		"query": "What is the compression ratio?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/68": {
		"query": "I want to benchmark my tensorrt model.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/69": {
		"query": "I'd like to know how much memory is consumed to run my model with benchmark.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/70": {
		"query": "Can you benchmark my model?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/71": {
		"query": "Show me how to set fx model.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/72": {
		"query": "How to set the compression method?",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/73": {
		"query": "How to set the environment configuration with seed?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/74": {
		"query": "How to check the latency of my model on the device? Data type should be int8.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize the Trainer.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/75": {
		"query": "What is the framework of the model?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/76": {
		"query": "Convert model with target framework tensorrt.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/77": {
		"query": "Give me a code snippet to set training configuration.",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/78": {
		"query": "Show me the code snippet for pruning the model.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/79": {
		"query": "Prune custom model.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/80": {
		"query": "Convert model to run on intel-xeon.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/81": {
		"query": "Train epoch has to be 200. I have two gpus.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/82": {
		"query": "How to train the model?",
		"retrieved_APIs": {
			"API_1": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	}
}