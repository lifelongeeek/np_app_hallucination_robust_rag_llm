{
	"PyNPEval/0": {
		"query": "How can I benchmark a model on a Jetson-Nano device? input model path is 'best.onnx', target_data_type is fp16.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/2": {
		"query": "How to set the environment configuration with seed 42?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/3": {
		"query": "Can you provide an example of how to convert a pytorch model to the onnx framework?",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/4": {
		"query": "Give me a code snippet to train yolox model for image classification. I have only one gpu and project name is 'yolox_cls'.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/5": {
		"query": "How can I compress a model automatically? Compression ratio should be 0.6 and model's framework is onnx. Input shape of the model is [1, 3, 224, 224].",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/6": {
		"query": "Show me how to initialize Compressor instance.",
		"retrieved_APIs": {
			"API_1": "NetsPresso.compressor(): Initialize and return a Compressor instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
			"API_2": "Compressor(token_handler: TokenHandler): Initialize the Compressor.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/7": {
		"query": "Can you provide an example of how to set the logging configuration? I want to set validation_epoch to 20.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/8": {
		"query": "I want to set the augmentation configs with RandomCrop, Resize, ColorJitter.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/9": {
		"query": "Show me a code snippet to set a compression method to L2 pruning.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/11": {
		"query": "Show me how to set fx model. model path is 'model.pt'.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/13": {
		"query": "Prune the onnx model with L2 norm and compression ratio is 0.3. model path is 'best.onnx', output_dir is './output' and input shape is [1, 3, 96, 96].",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/14": {
		"query": "Give me a code snippet to train a model for the image segmentation task. model_name is efficientformer. I have 4 gpus and project_name is 'seg_model'. Set dataset config to default.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/15": {
		"query": "I want to benchmark my tensorrt model on jetson nano 4.6 device.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/16": {
		"query": "How to train the SegFormer for a image segmetation task?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/17": {
		"query": "Code snippet to training MobileViT for a image classification task and converting it to tflite model. An then prune the trained model with nuclear norm and compression ratio 0.4.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/18": {
		"query": "Show me an example to train ViT for image classification task. Train epoch has to be 200. I have two gpus and project name is 'cls_ViT'.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/19": {
		"query": "How to check the latency of my onnx model on jetson agx orin device? Data type should be int8.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize the Trainer.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/20": {
		"query": "Can you provide an example of how to use the Converter.convert_model() function to convert a model? Here's parameters. input_model_path:'best.pt' \noutput_dir='./output' \ntarget_framework: onnx \ntarget_device_name:RaspberryPi5",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/21": {
		"query": "How to set batch size to 32 and use Adagrad optimizer?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/23": {
		"query": "How can I set the output directory of training results in logging config?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/24": {
		"query": "How can I get the information about a specific compression?",
		"retrieved_APIs": {
			"API_1": "Compressor.get_compression(compression_id: str): Get information about a compression. Returns the information about the compression.\n\n\nParameters\n----------\ncompression_id (str): The ID of the compression.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_info = compressor.get_compression(compression_id='YOUR_COMPRESSION_ID')",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/25": {
		"query": "Give me a code snippet to set training configuration. train epochs to 200 and valid epochs to 10.",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/26": {
		"query": "How to benchmark custom tensorflow model on raspberry pi 4b device?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
			"API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/27": {
		"query": "Prune custom pytorch model automatically. Model path is 'model.pt', output directory is './saved', compression ratio is 0.7. and input shape of the model would be [1, 3, 96, 96].",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/28": {
		"query": "How to check the inference latency with my custom onnx model on jetson nano device? model path is 'resnet18.onnx', target data type is fp16.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/29": {
		"query": "I want to know how to compress my custom onnx model with singular value decomposition method. Model path is 'my_model.onnx', compression ratios is 0.6, output_dir is './logs' and input shape is [1, 3, 224, 224].",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/30": {
		"query": "How to convert pytorch model to onnx model? Model path is 'best_ckpt.pt', target device is aws t4 and output directory is './output'.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/31": {
		"query": "I want to convert keras model to tflite.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/32": {
		"query": "I want to convert my onnx model to tensorrt model. model path is 'ckpt/last.onnx', output directory is './converted' and target device is rzv2l_avnet.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/33": {
		"query": "Show me the code snippet to pruning the pytorch model. Here are some conditions.\n 1. Compression method: tucker decomposition \n2. Compression ratio: 0.4.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/34": {
		"query": "I want to benchmark my model with int8. I have a onnx model and target framework is tflite, model path is './last.onnx' and target device is raspberry pi 4b.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/35": {
		"query": "How to train my efficientformer fx model? Train epoch should be 100 and I will use 4 gpus.",
		"retrieved_APIs": {
			"API_1": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/37": {
		"query": "Show me how to convert yolox onnx model to tensorrt model. Model path is 'mymodel.onnx' and output directory is './converted'. Optimize the model for target device AWS-T4.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/38": {
		"query": "Convert custom onnx model to run on intel-xeon. model path is 'models/model.onnx', output directory is './output', target framework is tensorrt.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/39": {
		"query": "I'd like to know how much memory is consumed to run my tflite model with benchmark. Model path is 'yolox.tflite' and data type is fp16. The device to check is jetson nano 4.4.1.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/40": {
		"query": "Give me the code to check the inference latency benchmark of custom tflite model. Target device is rzv2m, input model path is 'my_model.tflite', target data type is int8.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/41": {
		"query": "Train yolox model for image classification. Here are requirements. \n1. Epoch: 300 \n2. Batch size: 32 \n3. Augmentation: RandomCrop, RandomHorizontalFlip \n4. Optimizer: SGD\n 5. Scheduler: StepLR\n 6. gpus: 0, 1, 2, 3\n7. Project name: cls_yolox\n8.YOLOX-S \n9.image size: [256, 256]",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/42": {
		"query": "I'd like to know how to set the compression method with belows.\n1. Policy: sum\n2. GroupPolicy: count\n3. LayerNorm: linear scaling",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/44": {
		"query": "Give me the code snippet to set layer normalization method to linear scaling.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/45": {
		"query": "How to set the dataset? dataset name is 'custom dataset', root path is './data', train images are at './data/image/train' and train labels are at './data/label/train'.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/46": {
		"query": "I want to save the result in csv format. How to do that?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/48": {
		"query": "I want to use SGD optimizer and StepLR scheduler.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	},
	"PyNPEval/49": {
		"query": "How to set augmentation config with Pad, RandomVerticalFlip, RandomMixup?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": true,
			"reason_for_unanswerable": "na"
		}
	}
}