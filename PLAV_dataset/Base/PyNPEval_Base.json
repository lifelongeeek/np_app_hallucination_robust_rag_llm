{
    "PyNPEval/0": {
        "original_query": "How can I benchmark a model on a Jetson-Nano device? input model path is 'best.onnx', target_data_type is fp16.",
        "retrieved_APIs": {
            "API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How can I benchmark a device?",
            "How can I benchmark a model?",
            "How can I benchmark a model on a device?",
            "How can I benchmark a model on a Jetson-Nano device?"
        ]
    },
    "PyNPEval/2": {
        "original_query": "How to set the environment configuration with seed 42?",
        "retrieved_APIs": {
            "API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
            "API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
        },
        "gold_APIs": {
            "00012": "Method Name\n--------\nTrainer.set_environment_config\n\n\nDescription\n--------\nSet the environment configuration.\n\n\nParameters\n--------\nseed (int, optional): Random seed. Defaults to 1.\n\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to set the environment configuration with seed?",
            "How to set the environment configuration with 42?"
        ]
    },
    "PyNPEval/3": {
        "original_query": "Can you provide an example of how to convert a pytorch model to the onnx framework?",
        "retrieved_APIs": {
            "API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Provide an example of how to convert model.",
            "Can you convert model to the other framework?"
        ]
    },
    "PyNPEval/4": {
        "original_query": "Give me a code snippet to train yolox model for image classification. I have only one gpu and project name is 'yolox_cls'.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["Give me a code snippet for image classification."]
    },
    "PyNPEval/5": {
        "original_query": "How can I compress a model automatically? Compression ratio should be 0.6 and model's framework is onnx. Input shape of the model is [1, 3, 224, 224].",
        "retrieved_APIs": {
            "API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00019": "Method Name\n--------\nCompressor.automatic_compression\n\n\nDescription\n--------\nCompress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local path to save the compressed model.\n\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\n\nframework (Framework, optional): The framework of the model.\n\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How can I compress a model?",
            "What is the compression ratio?",
            "What is the framework of the model?",
            "What is the input shape of the model?"
        ]
    },
    "PyNPEval/6": {
        "original_query": "Show me how to initialize Compressor instance.",
        "retrieved_APIs": {
            "API_1": "NetsPresso.compressor(): Initialize and return a Compressor instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
            "API_2": "Compressor(token_handler: TokenHandler): Initialize the Compressor.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00002": "Method Name\n--------\nNetsPresso.compressor\n\n\nDescription\n--------\nInitialize and return a Compressor instance.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n```"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["Show me how to initialize instance."]
    },
    "PyNPEval/7": {
        "original_query": "Can you provide an example of how to set the logging configuration? I want to set validation_epoch to 20.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
            "API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
        },
        "gold_APIs": {
            "00011": "Method Name\n--------\nTrainer.set_logging_config\n\n\nDescription\n--------\nSet the logging configuration.\n\n\nParameters\n--------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\n\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\n\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\n\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\n\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\n\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\n\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\n\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\n\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Can you provide an example of how to set the configuration?",
            "Can you provide an example of how to set the logging?"
        ]
    },
    "PyNPEval/8": {
        "original_query": "I want to set the augmentation configs with RandomCrop, Resize, ColorJitter.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
            "API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_4": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00010": "Method Name\n--------\nTrainer.set_augmentation_config\n\n\nDescription\n--------\nSet the augmentation configuration for training.\n\n\nParameters\n--------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\n\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\n\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["Can you set the augmentation configs?"]
    },
    "PyNPEval/9": {
        "original_query": "Show me a code snippet to set a compression method to L2 pruning.",
        "retrieved_APIs": {
            "API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
            "API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_5": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)"
        },
        "gold_APIs": {
            "00016": "Method Name\n--------\nCompressor.select_compression_method\n\n\nDescription\n--------\nSelect a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n--------\nmodel_id (str): The ID of the model.\n\ncompression_method (CompressionMethod): The selected compression method.\n\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass Policy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    BACKWARD = 'backward'\n```\n\n```python\nclass GroupPolicy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    COUNT = 'count'\n    NONE = 'none'\n```\n\n```python\nclass LayerNorm(str, Enum):\n    NONE = 'none'\n    STANDARD_SCORE = 'standard_score'\n    TSS_NORM = 'tss_norm'\n    LINEAR_SCALING = 'linear_scaling'\n    SOFTMAX_NORM = 'softmax_norm'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Show me a code snippet to set a compression method.",
            "Show me a code snippet to set a compression method to pruning."
        ]
    },
    "PyNPEval/11": {
        "original_query": "Show me how to set fx model. model path is 'model.pt'.",
        "retrieved_APIs": {
            "API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
            "API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')"
        },
        "gold_APIs": {
            "00008": "Method Name\n--------\nTrainer.set_fx_model\n\n\nDescription\n--------\nSet the FX model path for retraining.\n\n\nParameters\n--------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Show me how to set fx model.",
            "How to set fx model?"
        ]
    },
    "PyNPEval/13": {
        "original_query": "Prune the onnx model with L2 norm and compression ratio is 0.3. model path is 'best.onnx', output_dir is './output' and input shape is [1, 3, 96, 96].",
        "retrieved_APIs": {
            "API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00020": "Method Name\n--------\nCompressor.recommendation_compression\n\n\nDescription\n--------\nCompress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n--------\ncompression_method (CompressionMethod): The selected compression method.\n\nrecommendation_method (RecommendationMethod): The selected recommendation method.\n\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\n\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local path to save the compressed model.\n\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\n\nframework (Framework, optional): The framework of the model.\n\noptions(Options, optional): The options for pruning method.\n\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass RecommendationMethod(str, Enum):\n    SLAMP = 'slamp'\n    VBMF = 'vbmf'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Prune the model with L2 norm.",
            "Prune the model with compression ratio 0.3."
        ]
    },
    "PyNPEval/14": {
        "original_query": "Give me a code snippet to train a model for the image segmentation task. model_name is efficientformer. I have 4 gpus and project_name is 'seg_model'. Set dataset config to default.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_3": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
        },
        "gold_APIs": {
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Give me a code snippet to train a model.",
            "Give me a code snippet to train a model for the image segmentation task."
        ]
    },
    "PyNPEval/15": {
        "original_query": "I want to benchmark my tensorrt model on jetson nano 4.6 device.",
        "retrieved_APIs": {
            "API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "I want to benchmark my model on device.",
            "Can you benchmark my model?",
            "I want to benchmark my tensorrt model."
        ]
    },
    "PyNPEval/16": {
        "original_query": "How to train the SegFormer for a image segmetation task?",
        "retrieved_APIs": {
            "API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
            "API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_4": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How to train SegFormer?"]
    },
    "PyNPEval/17": {
        "original_query": "Code snippet to training MobileViT for a image classification task and converting it to tflite model. An then prune the trained model with nuclear norm and compression ratio 0.4.",
        "retrieved_APIs": {
            "API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_5": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')"
        },
        "gold_APIs": {
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n",
            "00020": "Method Name\n--------\nCompressor.recommendation_compression\n\n\nDescription\n--------\nCompress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n--------\ncompression_method (CompressionMethod): The selected compression method.\n\nrecommendation_method (RecommendationMethod): The selected recommendation method.\n\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\n\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local path to save the compressed model.\n\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\n\nframework (Framework, optional): The framework of the model.\n\noptions(Options, optional): The options for pruning method.\n\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass RecommendationMethod(str, Enum):\n    SLAMP = 'slamp'\n    VBMF = 'vbmf'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n",
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Code snippet to train MobileViT.",
            "Code snippet to convert to tflite model.",
            "Code snippet to prune the trained model."
        ]
    },
    "PyNPEval/18": {
        "original_query": "Show me an example to train ViT for image classification task. Train epoch has to be 200. I have two gpus and project name is 'cls_ViT'.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
            "API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
        },
        "gold_APIs": {
            "00009": "Method Name\n--------\nTrainer.set_training_config\n\n\nDescription\n--------\nSet the training configuration.\n\n\nParameters\n--------\noptimizer: The configuration of optimizer.\n\nscheduler: The configuration of learning rate scheduler.\n\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\n\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n",
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Train epoch has to be 200. I have two gpus.",
            "Show me an example to train for image classification task. Project name is 'my_proj'.",
            "Show me an example to train ViT for image classification task. Train epoch has to be 100."
        ]
    },
    "PyNPEval/19": {
        "original_query": "How to check the latency of my onnx model on jetson agx orin device? Data type should be int8.",
        "retrieved_APIs": {
            "API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize the Trainer.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
            "API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
            "API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to check the latency of my model on the device?",
            "How to check the latency of my onnx model on the device?",
            "How to check the latency of my model on the device? Data type should be int8."
        ]
    },
    "PyNPEval/20": {
        "original_query": "Can you provide an example of how to use the Converter.convert_model() function to convert a model? Here's parameters. input_model_path:'best.pt' \noutput_dir='./output' \ntarget_framework: onnx \ntarget_device_name:RaspberryPi5",
        "retrieved_APIs": {
            "API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Can you provide an example of how to use the Converter.convert_model() function?",
            "Can you provide an example of how to convert a model?",
            "Can you provide an example of how to use the convert function?"
        ]
    },
    "PyNPEval/21": {
        "original_query": "How to set batch size to 32 and use Adagrad optimizer?",
        "retrieved_APIs": {
            "API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
            "API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00009": "Method Name\n--------\nTrainer.set_training_config\n\n\nDescription\n--------\nSet the training configuration.\n\n\nParameters\n--------\noptimizer: The configuration of optimizer.\n\nscheduler: The configuration of learning rate scheduler.\n\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\n\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to set batch size and use optimizer?",
            "How to use Adagrad optimizer?"
        ]
    },
    "PyNPEval/23": {
        "original_query": "How can I set the output directory of training results in logging config?",
        "retrieved_APIs": {
            "API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
        },
        "gold_APIs": {
            "00011": "Method Name\n--------\nTrainer.set_logging_config\n\n\nDescription\n--------\nSet the logging configuration.\n\n\nParameters\n--------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\n\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\n\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\n\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\n\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\n\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\n\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\n\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\n\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How can I set the output directory?"]
    },
    "PyNPEval/24": {
        "original_query": "How can I get the information about a specific compression?",
        "retrieved_APIs": {
            "API_1": "Compressor.get_compression(compression_id: str): Get information about a compression. Returns the information about the compression.\n\n\nParameters\n----------\ncompression_id (str): The ID of the compression.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_info = compressor.get_compression(compression_id='YOUR_COMPRESSION_ID')",
            "API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_3": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
            "API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00018": "Method Name\n--------\nCompressor.get_compression\n\n\nDescription\n--------\nGet information about a compression. Returns the information about the compression.\n\n\nParameters\n--------\ncompression_id (str): The ID of the compression.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_info = compressor.get_compression(compression_id='YOUR_COMPRESSION_ID')\n```"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How can I get the information about compression?"]
    },
    "PyNPEval/25": {
        "original_query": "Give me a code snippet to set training configuration. train epochs to 200 and valid epochs to 10.",
        "retrieved_APIs": {
            "API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
        },
        "gold_APIs": {
            "00009": "Method Name\n--------\nTrainer.set_training_config\n\n\nDescription\n--------\nSet the training configuration.\n\n\nParameters\n--------\noptimizer: The configuration of optimizer.\n\nscheduler: The configuration of learning rate scheduler.\n\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\n\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Give me a code snippet to set training configuration."
        ]
    },
    "PyNPEval/26": {
        "original_query": "How to benchmark custom tensorflow model on raspberry pi 4b device?",
        "retrieved_APIs": {
            "API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
            "API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to benchmark on device?",
            "How to benchmark custom model?",
            "How to benchmark on raspberry pi 4b device?",
            "How to benchmark custom tensorflow model?"
        ]
    },
    "PyNPEval/27": {
        "original_query": "Prune custom pytorch model automatically. Model path is 'model.pt', output directory is './saved', compression ratio is 0.7. and input shape of the model would be [1, 3, 96, 96].",
        "retrieved_APIs": {
            "API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00019": "Method Name\n--------\nCompressor.automatic_compression\n\n\nDescription\n--------\nCompress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local path to save the compressed model.\n\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\n\nframework (Framework, optional): The framework of the model.\n\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["Prune model automatically.", "Prune custom model."]
    },
    "PyNPEval/28": {
        "original_query": "How to check the inference latency with my custom onnx model on jetson nano device? model path is 'resnet18.onnx', target data type is fp16.",
        "retrieved_APIs": {
            "API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to check the inference latency with my custom model on device?"
        ]
    },
    "PyNPEval/29": {
        "original_query": "I want to know how to compress my custom onnx model with singular value decomposition method. Model path is 'my_model.onnx', compression ratios is 0.6, output_dir is './logs' and input shape is [1, 3, 224, 224].",
        "retrieved_APIs": {
            "API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00020": "Method Name\n--------\nCompressor.recommendation_compression\n\n\nDescription\n--------\nCompress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n--------\ncompression_method (CompressionMethod): The selected compression method.\n\nrecommendation_method (RecommendationMethod): The selected recommendation method.\n\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\n\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local path to save the compressed model.\n\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\n\nframework (Framework, optional): The framework of the model.\n\noptions(Options, optional): The options for pruning method.\n\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass RecommendationMethod(str, Enum):\n    SLAMP = 'slamp'\n    VBMF = 'vbmf'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "I want to know how to compress my custom model with singular value decomposition method.",
            "I want to know how to compress my custom model with singular value decomposition method. Model path is 'my_model.onnx'.",
            "I want to know how to compress my custom onnx model. Output_dir is './logs' and input shape is [1, 3, 224, 224]."
        ]
    },
    "PyNPEval/30": {
        "original_query": "How to convert pytorch model to onnx model? Model path is 'best_ckpt.pt', target device is aws t4 and output directory is './output'.",
        "retrieved_APIs": {
            "API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to convert pytorch model to onnx?",
            "How to convert pytorch model?"
        ]
    },
    "PyNPEval/31": {
        "original_query": "I want to convert keras model to tflite.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
            "API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["I want to convert model to tflite."]
    },
    "PyNPEval/32": {
        "original_query": "I want to convert my onnx model to tensorrt model. model path is 'ckpt/last.onnx', output directory is './converted' and target device is rzv2l_avnet.",
        "retrieved_APIs": {
            "API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["Convert my onnx model to tensorrt model."]
    },
    "PyNPEval/33": {
        "original_query": "Show me the code snippet to pruning the pytorch model. Here are some conditions.\n 1. Compression method: tucker decomposition \n2. Compression ratio: 0.4.",
        "retrieved_APIs": {
            "API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_2": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
        },
        "gold_APIs": {
            "00016": "Method Name\n--------\nCompressor.select_compression_method\n\n\nDescription\n--------\nSelect a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n--------\nmodel_id (str): The ID of the model.\n\ncompression_method (CompressionMethod): The selected compression method.\n\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass Policy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    BACKWARD = 'backward'\n```\n\n```python\nclass GroupPolicy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    COUNT = 'count'\n    NONE = 'none'\n```\n\n```python\nclass LayerNorm(str, Enum):\n    NONE = 'none'\n    STANDARD_SCORE = 'standard_score'\n    TSS_NORM = 'tss_norm'\n    LINEAR_SCALING = 'linear_scaling'\n    SOFTMAX_NORM = 'softmax_norm'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Show me the code snippet for pruning the model.",
            "Can you provide the code snippet for pruning?"
        ]
    },
    "PyNPEval/34": {
        "original_query": "I want to benchmark my model with int8. I have a onnx model and target framework is tflite, model path is './last.onnx' and target device is raspberry pi 4b.",
        "retrieved_APIs": {
            "API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "I want to benchmark my model with int8.",
            "I have a model and target framework is tflite. And target device is raspberry pi 4b."
        ]
    },
    "PyNPEval/35": {
        "original_query": "How to train my efficientformer fx model? Train epoch should be 100 and I will use 4 gpus.",
        "retrieved_APIs": {
            "API_1": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')",
            "API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
            "API_4": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')",
            "API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
        },
        "gold_APIs": {
            "00008": "Method Name\n--------\nTrainer.set_fx_model\n\n\nDescription\n--------\nSet the FX model path for retraining.\n\n\nParameters\n--------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n",
            "00009": "Method Name\n--------\nTrainer.set_training_config\n\n\nDescription\n--------\nSet the training configuration.\n\n\nParameters\n--------\noptimizer: The configuration of optimizer.\n\nscheduler: The configuration of learning rate scheduler.\n\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\n\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n",
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How to train the model?"]
    },
    "PyNPEval/37": {
        "original_query": "Show me how to convert yolox onnx model to tensorrt model. Model path is 'mymodel.onnx' and output directory is './converted'. Optimize the model for target device AWS-T4.",
        "retrieved_APIs": {
            "API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "How to convert onnx model to tensorrt model?",
            "How to convert yolox onnx model."
        ]
    },
    "PyNPEval/38": {
        "original_query": "Convert custom onnx model to run on intel-xeon. model path is 'models/model.onnx', output directory is './output', target framework is tensorrt.",
        "retrieved_APIs": {
            "API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00022": "Method Name\n--------\nConverter.convert_model\n\n\nDescription\n--------\nConvert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\noutput_dir (str): The local folder path to save the converted model.\n\ntarget_framework (Union[str, Framework]): The target framework name.\n\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\n\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\n\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Framework(str, Enum):\n    TENSORFLOW_KERAS = 'tensorflow_keras'\n    TENSORFLOW = 'saved_model'\n    PYTORCH = 'pytorch'\n    ONNX = 'onnx'\n    TENSORRT = 'tensorrt'\n    OPENVINO = 'openvino'\n    TENSORFLOW_LITE = 'tensorflow_lite'\n    DRPAI = 'drpai'\n```\n\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Convert model to run on intel-xeon.",
            "Convert model with target framework tensorrt."
        ]
    },
    "PyNPEval/39": {
        "original_query": "I'd like to know how much memory is consumed to run my tflite model with benchmark. Model path is 'yolox.tflite' and data type is fp16. The device to check is jetson nano 4.4.1.",
        "retrieved_APIs": {
            "API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "I'd like to know how much memory is consumed to run my model with benchmark.",
            "How much memory is consumed to run the model with benchmark? Model path is 'yolox.tflite' and data type is fp16"
        ]
    },
    "PyNPEval/40": {
        "original_query": "Give me the code to check the inference latency benchmark of custom tflite model. Target device is rzv2m, input model path is 'my_model.tflite', target data type is int8.",
        "retrieved_APIs": {
            "API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
        },
        "gold_APIs": {
            "00024": "Method Name\n--------\nBenchmarker.benchmark_model\n\n\nDescription\n--------\nBenchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n--------\ninput_model_path (str): The file path where the model is located.\n\ntarget_device_name (DeviceName): Target device name.\n\ntarget_data_type (DataType): Data type of the model.\n\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\n\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\n\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass DeviceName(str, Enum):\n    RASPBERRY_PI_5 = 'RaspberryPi5'\n    RASPBERRY_PI_4B = 'RaspberryPi4B'\n    RASPBERRY_PI_3B_PLUS = 'RaspberryPi3BPlus'\n    RASPBERRY_PI_ZERO_W = 'RaspberryPi-ZeroW'\n    RASPBERRY_PI_ZERO_2W = 'RaspberryPi-Zero2W'\n    RENESAS_RZ_V2L = 'rzv2l_avnet'\n    RENESAS_RZ_V2M = 'rzv2m'\n    JETSON_NANO = 'Jetson-Nano'\n    JETSON_TX2 = 'Jetson-Tx2'\n    JETSON_XAVIER = 'Jetson-Xavier'\n    JETSON_NX = 'Jetson-Nx'\n    JETSON_AGX_ORIN = 'Jetson-AGX-Orin'\n    AWS_T4 = 'AWS-T4'\n    INTEL_XEON_W_2233 = 'Intel-Xeon'\n    ALIF_ENSEMBLE_E7_DEVKIT_GEN2 = 'Ensemble-E7-DevKit-Gen2'\n    RENESAS_RA8D1 = 'Renesas-RA8D1'\n    ARM_ETHOS_U_SERIES = 'Arm Virtual Hardware Ethos-U Series'\n```\n\n```python\nclass SoftwareVersion(str, Enum):\n    JETPACK_4_4_1 = '4.4.1-b50'\n    JETPACK_4_6 = '4.6-b199'\n    JETPACK_5_0_1 = '5.0.1-b118'\n    JETPACK_5_0_2 = '5.0.2-b231'\n```\n\n```python\nclass HardwareType(str, Enum):\n    HELIUM = 'helium'\n```\n\n```python\nclass DataType(str, Enum):\n    FP32 = 'FP32'\n    FP16 = 'FP16'\n    INT8 = 'INT8'\n    NONE = ''\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Give me the code to check the inference latency benchmark.",
            "Give me the code to check the inference latency benchmark of custom model.",
            "Give me the code to check the inference latency benchmark of custom tflite model on rzv2m."
        ]
    },
    "PyNPEval/41": {
        "original_query": "Train yolox model for image classification. Here are requirements. \n1. Epoch: 300 \n2. Batch size: 32 \n3. Augmentation: RandomCrop, RandomHorizontalFlip \n4. Optimizer: SGD\n 5. Scheduler: StepLR\n 6. gpus: 0, 1, 2, 3\n7. Project name: cls_yolox\n8.YOLOX-S \n9.image size: [256, 256]",
        "retrieved_APIs": {
            "API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
            "API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
            "API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
            "API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
        },
        "gold_APIs": {
            "00009": "Method Name\n--------\nTrainer.set_training_config\n\n\nDescription\n--------\nSet the training configuration.\n\n\nParameters\n--------\noptimizer: The configuration of optimizer.\n\nscheduler: The configuration of learning rate scheduler.\n\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\n\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n",
            "00010": "Method Name\n--------\nTrainer.set_augmentation_config\n\n\nDescription\n--------\nSet the augmentation configuration for training.\n\n\nParameters\n--------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\n\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\n\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n",
            "00013": "Method Name\n--------\nTrainer.train\n\n\nDescription\n--------\nTrain the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n--------\ngpus (str): GPU ids to use, separated by commas.\n\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Train model for image classification.",
            "Train yolox model."
        ]
    },
    "PyNPEval/42": {
        "original_query": "I'd like to know how to set the compression method with belows.\n1. Policy: sum\n2. GroupPolicy: count\n3. LayerNorm: linear scaling",
        "retrieved_APIs": {
            "API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
            "API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
        },
        "gold_APIs": {
            "00016": "Method Name\n--------\nCompressor.select_compression_method\n\n\nDescription\n--------\nSelect a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n--------\nmodel_id (str): The ID of the model.\n\ncompression_method (CompressionMethod): The selected compression method.\n\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass Policy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    BACKWARD = 'backward'\n```\n\n```python\nclass GroupPolicy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    COUNT = 'count'\n    NONE = 'none'\n```\n\n```python\nclass LayerNorm(str, Enum):\n    NONE = 'none'\n    STANDARD_SCORE = 'standard_score'\n    TSS_NORM = 'tss_norm'\n    LINEAR_SCALING = 'linear_scaling'\n    SOFTMAX_NORM = 'softmax_norm'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "I'd like to know how to set the compression method.",
            "How to set the compression method?"
        ]
    },
    "PyNPEval/44": {
        "original_query": "Give me the code snippet to set layer normalization method to linear scaling.",
        "retrieved_APIs": {
            "API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
            "API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
            "API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
        },
        "gold_APIs": {
            "00016": "Method Name\n--------\nCompressor.select_compression_method\n\n\nDescription\n--------\nSelect a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n--------\nmodel_id (str): The ID of the model.\n\ncompression_method (CompressionMethod): The selected compression method.\n\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass CompressionMethod(str, Enum):\n    PR_L2 = 'PR_L2'\n    PR_GM = 'PR_GM'\n    PR_NN = 'PR_NN'\n    PR_ID = 'PR_ID'\n    FD_TK = 'FD_TK'\n    FD_CP = 'FD_CP'\n    FD_SVD = 'FD_SVD'\n```\n\n```python\nclass Policy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    BACKWARD = 'backward'\n```\n\n```python\nclass GroupPolicy(str, Enum):\n    SUM = 'sum'\n    AVERAGE = 'average'\n    COUNT = 'count'\n    NONE = 'none'\n```\n\n```python\nclass LayerNorm(str, Enum):\n    NONE = 'none'\n    STANDARD_SCORE = 'standard_score'\n    TSS_NORM = 'tss_norm'\n    LINEAR_SCALING = 'linear_scaling'\n    SOFTMAX_NORM = 'softmax_norm'\n```\n\n```python\nclass Options(OptionsBase):\n    policy: policy_literal = Field(Policy.AVERAGE, description='Policy')\n    layer_norm: layernorm_literal = Field(LayerNorm.STANDARD_SCORE, description='layer Norm')\n    group_policy: grouppolicy_literal = Field(GroupPolicy.AVERAGE, description='Group Policy')\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": [
            "Give me the code snippet to set method to linear scaling."
        ]
    },
    "PyNPEval/45": {
        "original_query": "How to set the dataset? dataset name is 'custom dataset', root path is './data', train images are at './data/image/train' and train labels are at './data/label/train'.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
            "API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
        },
        "gold_APIs": {
            "00006": "Method Name\n--------\nTrainer.set_dataset_config\n\n\nDescription\n--------\nSet the dataset configuration for the Trainer\n\n\nParameters\n--------\nname (str): The name of dataset.\n\nroot_path (str): Root directory of dataset.\n\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\n\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\n\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\n\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\n\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How to set the dataset?"]
    },
    "PyNPEval/46": {
        "original_query": "I want to save the result in csv format. How to do that?",
        "retrieved_APIs": {
            "API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
            "API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
            "API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
        },
        "gold_APIs": {
            "00011": "Method Name\n--------\nTrainer.set_logging_config\n\n\nDescription\n--------\nSet the logging configuration.\n\n\nParameters\n--------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\n\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\n\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\n\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\n\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\n\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\n\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\n\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\n\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How to save the result?"]
    },
    "PyNPEval/48": {
        "original_query": "I want to use SGD optimizer and StepLR scheduler.",
        "retrieved_APIs": {
            "API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
            "API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
            "API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')"
        },
        "gold_APIs": {
            "00009": "Method Name\n--------\nTrainer.set_training_config\n\n\nDescription\n--------\nSet the training configuration.\n\n\nParameters\n--------\noptimizer: The configuration of optimizer.\n\nscheduler: The configuration of learning rate scheduler.\n\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\n\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\noptimizers: Adadelta, Adagrad, Adam, Adamax, AdamW, RMSprop, SGD\n\n\nschedulers: StepLR, PolynomialLRWithWarmUp, CosineAnnealingLRWithCustomWarmUp, CosineAnnealingWarmRestartsWithCustomWarmUp\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["I want to use optimizer and scheduler."]
    },
    "PyNPEval/49": {
        "original_query": "How to set augmentation config with Pad, RandomVerticalFlip, RandomMixup?",
        "retrieved_APIs": {
            "API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
            "API_2": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
            "API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
            "API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
            "API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
        },
        "gold_APIs": {
            "00010": "Method Name\n--------\nTrainer.set_augmentation_config\n\n\nDescription\n--------\nSet the augmentation configuration for training.\n\n\nParameters\n--------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\n\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\n\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n--------\n```python\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n```\n\n\nParameter Candidates\n--------\n```python\nclass Task(str, Enum):\n    IMAGE_CLASSIFICATION = 'classification'\n    OBJECT_DETECTION = 'detection'\n    SEMANTIC_SEGMENTATION = 'segmentation'\n```\n\n\naugmentations: ColorJitter, Pad, RandomCrop, RandomCutmix, RandomHorizontalFlip, RandomMixup, RandomResizedCrop, RandomVerticalFlip, Resize, TrivialAugmentWide\n"
        },
        "annotation": {
            "answerable": true,
            "reason_for_unanswerable": "na"
        },
        "corrupted_query": ["How to set augmentation config?"]
    }
}
