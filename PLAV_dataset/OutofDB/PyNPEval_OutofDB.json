{
	"PyNPEval/0": {
		"query": "I want to get the counts of distinctive values of the knowledgeframe. count_values implements this however I want to use its output somewhere else. How can I convert .count_values output to a monkey knowledgeframe. Use renaming_axis('distinctive_values') for name ('counts') of column from index and reseting_index return the final knowledgeframe",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/2": {
		"query": "How to convert an numset of strings to an numset of floats in beatnum? Return the final result",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/3": {
		"query": "Monkey knowledgeframe fillnone() only some columns in place This function fills all columns with 0 Return the changed knowledgeframe",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/4": {
		"query": "Finding non-numeric rows in knowledgeframe in monkey Return the raws that contain non-numeric values So to get the subKnowledgeFrame of rouges, (Note: the negation, ~, of the above finds the ones which have at least one rogue non-numeric):",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/5": {
		"query": "Removing columns with index 1 and 3 in beatnum If you ever want to remove more than one columns, you just pass indices of columns you want removed as a list to bn.remove_operation, like this:",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/6": {
		"query": "Attach the elements in the source IterDataPipe to the elements in the MapDataPipe.",
		"retrieved_APIs": {
			"API_1": "NetsPresso.compressor(): Initialize and return a Compressor instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
			"API_2": "Compressor(token_handler: TokenHandler): Initialize the Compressor.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/7": {
		"query": "Return the knowledgeframe with the rows with one or more NaN values",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/8": {
		"query": "How do I select the given columns and return the new KnowledgeFrame?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/9": {
		"query": "How to find the groups of consecutive elements in a BeatNum numset I have to cluster the consecutive elements from a BeatNum numset. Considering the following example a = [ 0, 47, 48, 49, 50, 97, 98, 99] The output should be a list of tuples as follows [(0), (47, 48, 49, 50), (97, 98, 99)] Here the difference is just one between the elements. It will be great if the difference can also be specified as a limit or a hardcoded number. Finally, return the number of consecutive elements in the numset.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/11": {
		"query": "I would simply like to slice the Data Frame and take the first n rows. Return the result",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/13": {
		"query": "How to get the index of a maximum element in a BeatNum numset along axis_value? Return the result",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/14": {
		"query": "I have a pandas dataframe I would like to se the diagonal to 0",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/15": {
		"query": "How to get the cumulative distribution function with BeatNum? set bins to 10 and then generate a cumulative sum of the hist_operation contents to variable hist self",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/16": {
		"query": "Averaging over every 3 elements of a beatnum numset I have a beatnum numset. I want to create a new numset which is the average over every consecutive triplet of elements. So the new numset will be a third of the size as the original. Return it",
		"retrieved_APIs": {
			"API_1": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/17": {
		"query": "I am trying to extract the last year (YY) of a fiscal date string in the format of YYYY-YY. e.g The last year of this '1999-00' would be 2000. I need a logic to include a case where if it is the end of the century then my employ method should add to the first two digits. the column_name is the column name of the knowledgeframe that contains the date strings. return the numerical Collections obj of the last year.",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/18": {
		"query": "How can I use change_shape_to to divide it into 4 chucks, such that it looks like this: I would like to change_shape_to a to (2, 4, 2, 4) and then switching_places it by (0, 2, 1, 3) to c",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/19": {
		"query": "How do I find all rows in a monkey KnowledgeFrame which have the max value for 'num' column, after grouping by 'Mt' column?",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize the Trainer.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_4": "NetsPresso.trainer(task: Optional[Union[str, Task]] = None, yaml_path: Optional[str] = None): Initialize and return a Trainer instance.\n\n\nParameters\n----------\ntask (Union[str, Task]], optional): The type of task (classification, detection, segmentation). Either 'task' or 'yaml_path' must be provided, but not both.\nyaml_path (str, optional): Path to the YAML configuration file. Either 'task' or 'yaml_path' must be provided, but not both.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)",
			"API_5": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/20": {
		"query": "Inverse of a matrix using beatnum and return it. Ibnut: matrix: beatnum numset, shape (n, n) Output: inverse: beatnum numset, shape (n, n)",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/21": {
		"query": "I generate a list of one dimensional beatnum numsets in a loop and later convert this list to a 2d beatnum numset. I would've preallocated a 2d beatnum numset if i knew the number of items ahead of time, but I don't, therefore I put everything in a list. s there a better way (performancewise) to go about the task of collecting sequential numerical data (in my case beatnum numsets) than putting them in a list and then making a beatnum.numset out of it (I am creating a new obj and copying the data)? Is there an \"expandable\" matrix data structure available in a well tested module?",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/23": {
		"query": "I need a general way to flatten that numset into a single numset of N elements, with N=every float in all the sub-numsets.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/24": {
		"query": "Put the above DataPipes into one list obj, and remove the last number from each element (e.g., \"1\" in \"dog1\")",
		"retrieved_APIs": {
			"API_1": "Compressor.get_compression(compression_id: str): Get information about a compression. Returns the information about the compression.\n\n\nParameters\n----------\ncompression_id (str): The ID of the compression.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_info = compressor.get_compression(compression_id='YOUR_COMPRESSION_ID')",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/25": {
		"query": "create a beatnum numset composed of a list [[8, 7, 2], [5, 6, 1], [8, 2, 6]]",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/26": {
		"query": "Assign indexs to the datepipe object.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "NetsPresso.benchmarker(): Initialize and return a Benchmarker instance.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()",
			"API_5": "Benchmarker(token_handler: TokenHandler, user_info: UserInfo): Initialize the Benchmarker.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nbenchmarker = netspresso.benchmarker()"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/27": {
		"query": "adding dictionary to data frame return the data frame",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/28": {
		"query": "I need to change the dtype of multiple columns but the knowledgeframe has different kind of dtypes. Some columns dtypes are float64 whereas some columns are int64 I need to change all float64 to float32.",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/29": {
		"query": "Return the row-index values of the knowledgeframe as a list",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/30": {
		"query": "You can specify a new column named `average_along_rows` that contains the average of each row. You also need to compute the average along the rows, so use axis=1. Finally, return the knowledgeframe with the new column.",
		"retrieved_APIs": {
			"API_1": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/31": {
		"query": "creating a new knowledgeframe of all same with kf_original one, but no any rows return the new knowledgeframe",
		"retrieved_APIs": {
			"API_1": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/32": {
		"query": "How do I create an numset where every entry is the same value? I know beatnum.create_ones() and beatnum.zeros() do this for 1's and 0's, but what about -1? the shape of the numset is (5, 5)",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/33": {
		"query": "Is there an efficient beatnum way to find each index where the value changes? You can get this functionality in beatnum by comparing each element with it's neighbor and then using bn.filter_condition(condition).",
		"retrieved_APIs": {
			"API_1": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_2": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_5": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/34": {
		"query": "I am using beatnum. I have a matrix with 1 column and N rows and I want to get an numset from with N elements. For example, if i have M = matrix([[1], [2], [3], [4]]), I want to get A = numset([1,2,3,4]). Return the numset",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/35": {
		"query": "Return the indices of the minimum values along (axis is zero).",
		"retrieved_APIs": {
			"API_1": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')",
			"API_2": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Trainer.set_fx_model(fx_model_path: str): Set the FX model path for retraining.\n\n\nParameters\n----------\nfx_model_path (str): The path to the FX model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_fx_model(fx_model_path='YOUR_MODEL_PATH')",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/37": {
		"query": "Is there a way to compare what elements in a exist in b? Return a numset of booleans, True if elements in a exist in b, False otherwise",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/38": {
		"query": "How to count values in a certain range in a Beatnum numset? the number of elements fulfilling 2 < x < 8 is:",
		"retrieved_APIs": {
			"API_1": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/39": {
		"query": "I want to check if all values in the columns of a beatnum numset/matrix are the same. A column shares a common value if all the values in that column are True: The below code checks if all values in the columns are the same using a == a[0,:] and axis=0",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_4": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/40": {
		"query": "One element is generated from each input Iterable DataPipes in turn, until the end when the shortest input DataPipe is used up.",
		"retrieved_APIs": {
			"API_1": "Benchmarker.benchmark_model(input_model_path: str, target_device_name: DeviceName, target_data_type: DataType = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, target_hardware_type: Optional[Union[str, HardwareType]] = None, wait_until_done: bool = True): Benchmark the specified model on the specified device. Returns model benchmark task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ntarget_device_name (DeviceName): Target device name.\ntarget_data_type (DataType): Data type of the model.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ntarget_hardware_type (Union[str, HardwareType], optional): Hardware type. Acceleration options for processing the model inference.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\nbenchmarker = netspresso.benchmarker()\nbenchmark_task = benchmarker.benchmark_model(\n    input_model_path='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt',\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.upload_model(input_model_path: str, input_shapes: List[Dict[str, int]] = None, framework: Framework = Framework.PYTORCH): Upload a model for compression. Returns uploaded model object.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\ninput_shapes (List[Dict[str, int]], optional): Input shapes of the model. Defaults to [].\nframework (Framework): The framework of the model.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/mobilenetv1.h5',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/41": {
		"query": "How can I join them using beatnum methods You can transpose and flatten the numsets:",
		"retrieved_APIs": {
			"API_1": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_4": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)",
			"API_5": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/42": {
		"query": "First we concatenate two datapipes and then repeat the concatenated datapipe three times.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_3": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/44": {
		"query": "According to the merge_fn, we zip the above two datapipes and keep the key True. Whatsmore, cycle the zipped datapipe three times.",
		"retrieved_APIs": {
			"API_1": "Compressor.select_compression_method(model_id: str, compression_method: CompressionMethod, options: Options = Options()): Select a compression method for a model. Returns the compression information for the selected compression method.\n\n\nParameters\n----------\nmodel_id (str): The ID of the model.\ncompression_method (CompressionMethod): The selected compression method.\noptions(Options, optional): The options for pruning method.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, Policy, LayerNorm, GroupPolicy, Options\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompression_info = compressor.select_compression_method(\n    model_id='YOUR_UPLOADED_MODEL_ID',\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)",
			"API_2": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)",
			"API_5": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/45": {
		"query": "I want to make all column headers in my monkey data frame lower case",
		"retrieved_APIs": {
			"API_1": "Trainer.set_dataset_config(name: str, root_path: str, train_image: str = 'images/train', train_label: str = 'labels/train', valid_image: str = 'images/val', valid_label: str = 'labels/val', id_mapping: Optional[Union[List[str], Dict[str, str]]] = None): Set the dataset configuration for the Trainer\n\n\nParameters\n----------\nname (str): The name of dataset.\nroot_path (str): Root directory of dataset.\ntrain_image (str, optional): The directory for training images. Should be relative path to root directory. Defaults to 'images/train'.\ntrain_label (str, optional): The directory for training labels. Should be relative path to root directory. Defaults to 'labels/train'.\nvalid_image (str, optional): The directory for validation images. Should be relative path to root directory. Defaults to 'images/val'.\nvalid_label (str, optional): The directory for validation labels. Should be relative path to root directory. Defaults to 'labels/val'.\nid_mapping (Union[List[str], Dict[str, str]], optional): ID mapping for the dataset. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n   root_path='/root/traffic-sign',\n   train_image='images/train',\n   train_label='labels/train',\n   valid_image='images/valid',\n   valid_label='labels/valid',\n   id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],\n)",
			"API_2": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_3": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Compressor.recommendation_compression(compression_method: CompressionMethod, recommendation_method: RecommendationMethod, recommendation_ratio: float, input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, options: Options = Options(), dataset_path: Optional[str] = None): Compress a recommendation-based model using the given compression and recommendation methods. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression_method (CompressionMethod): The selected compression method.\nrecommendation_method (RecommendationMethod): The selected recommendation method.\nrecommendation_ratio (float): The compression ratio recommended by the recommendation method.\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\noptions(Options, optional): The options for pruning method.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, RecommendationMethod\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.recommendation_compression(\n    compression_method=CompressionMethod.PR_L2,\n    recommendation_method=RecommendationMethod.SLAMP,\n    recommendation_ratio=0.5,\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/graphmodule_recommend',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/46": {
		"query": "Divide datapipes into 3 batches and discard if the last batch is not reached.",
		"retrieved_APIs": {
			"API_1": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_2": "Converter.convert_model(input_model_path: str, output_dir: str, target_framework: Union[str, Framework], target_device_name: Union[str, DeviceName], target_data_type: Union[str, DataType] = DataType.FP16, target_software_version: Optional[Union[str, SoftwareVersion]] = None, input_shape: Optional[InputShape] = None, dataset_path: Optional[str] = None, wait_until_done: bool = True): Convert a model to the specified framework. Returns model conversion task dictionary.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local folder path to save the converted model.\ntarget_framework (Union[str, Framework]): The target framework name.\ntarget_device_name (Union[str, DeviceName]): Target device name. Required if target_device is not specified.\ntarget_data_type (Union[str, DataType]): Data type of the model. Default is DataType.FP16.\ntarget_software_version (Union[str, SoftwareVersion], optional): Target software version. Required if target_device_name is one of the Jetson devices.\ninput_shape (InputShape, optional): Target input shape for conversion (e.g., dynamic batch to static batch).\ndataset_path (str, optional): Path to the dataset. Useful for certain conversions.\nwait_until_done (bool): If True, wait for the conversion result before returning the function. If False, request the conversion and return the function immediately.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import DeviceName, Framework, SoftwareVersion\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\nconverter = netspresso.converter()\nconversion_task = converter.convert_model(\n    input_model_path='./examples/sample_models/test.onnx',\n    output_dir='./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1',\n    target_framework=Framework.TENSORRT,\n    target_device_name=DeviceName.JETSON_AGX_ORIN,\n    target_software_version=SoftwareVersion.JETPACK_5_0_1,\n)",
			"API_3": "Compressor.compress_model(compression: CompressionInfo, output_dir: str, dataset_path: Optional[str] = None): Compress a model using the provided compression information. Returns source model and compressed model information.\n\n\nParameters\n----------\ncompression (CompressionInfo): The information about the compression.\noutput_dir (str): The local path to save the compressed model.\ndataset_path (str, optional): The path of the dataset used for nuclear norm compression method. Default is None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import CompressionMethod, GroupPolicy, LayerNorm, Options, Policy\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\n\nmodel = compressor.upload_model(\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n)\n\ncompression_info = compressor.select_compression_method(\n    model_id=model.model_id,\n    compression_method=CompressionMethod.PR_L2,\n    options=Options(\n        policy=Policy.AVERAGE,\n        layer_norm=LayerNorm.STANDARD_SCORE,\n        group_policy=GroupPolicy.AVERAGE,\n        reshape_channel_axis=-1,\n    ),\n)\n\nfor available_layer in compression_info.available_layers[:5]:\n    available_layer.values = [0.2]\n\ncompressed_model = compressor.compress_model(\n    compression=compression_info,\n    output_dir='./outputs/compressed/graphmodule_manual',\n)",
			"API_4": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_5": "Compressor.automatic_compression(input_model_path: str, output_dir: str, input_shapes: List[Dict[str, int]], framework: Framework = Framework.PYTORCH, compression_ratio: float = 0.5): Compress a model automatically based on the given compression ratio. Returns source model and compressed model information.\n\n\nParameters\n----------\ninput_model_path (str): The file path where the model is located.\noutput_dir (str): The local path to save the compressed model.\ninput_shapes (List[Dict[str, int]]): Input shapes of the model.\nframework (Framework, optional): The framework of the model.\ncompression_ratio (float, optional): The compression ratio for automatic compression. Defaults to 0.5.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ncompressor = netspresso.compressor()\ncompressed_model = compressor.automatic_compression(\n    input_shapes=[{'batch': 1, 'channel': 3, 'dimension': [224, 224]}],\n    input_model_path='./examples/sample_models/graphmodule.pt',\n    output_dir='./outputs/compressed/pytorch_automatic_compression_1',\n    compression_ratio=0.5,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/48": {
		"query": "Using IterableWrapper to the file url and HttpReader to read the file",
		"retrieved_APIs": {
			"API_1": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)",
			"API_2": "Trainer.set_model_config(model_name: str, img_size: int, use_pretrained: bool = True, load_head: bool = False, path: Optional[str] = None, fx_model_path: Optional[str] = None, optimizer_path: Optional[str] = None): Set the model configuration for the Trainer.\n\n\nParameters\n----------\nmodel_name (str): Name of the model.\nimg_size (int): Image size for the model.\nuse_pretrained (bool, optional): Whether to use a pre-trained model. Defaults to True.\nload_head (bool, optional): Whether to load the model head. Defaults to False.\npath (str, optional): Path to the model. Defaults to None.\nfx_model_path (str, optional): Path to the FX model. Defaults to None.\noptimizer_path (str, optional): Path to the optimizer. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "NetsPresso(email: str, password: str, verify_ssl: bool = True): Initialize NetsPresso instance and perform user authentication.\n\n\nParameters\n----------\nemail (str): User's email for authentication.\npassword (str): User's password for authentication.\nverify_ssl (bool): Flag to indicate whether SSL certificates should be verified. Defaults to True.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	},
	"PyNPEval/49": {
		"query": "I would like to piece a beatnum numset to obtain the i-th index in the last dimension. Is there a way I can obtain this piece for any numset without explicitly having to write the numset dimensions? There is ... or Ellipsis, which does exactly this Returns: beatnum numset",
		"retrieved_APIs": {
			"API_1": "Trainer.set_environment_config(seed: int = 1, num_workers: int = 4): Set the environment configuration.\n\n\nParameters\n----------\nseed (int, optional): Random seed. Defaults to 1.\nnum_workers (int, optional): The number of multi-processing workers to be used by the data loader. Defaults to 4.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_environment_config(seed=42, num_workers=8)",
			"API_2": "Trainer.set_augmentation_config(train_transforms: Optional[List] = None, train_mix_transforms: Optional[List] = None, inference_transforms: Optional[List] = None): Set the augmentation configuration for training.\n\n\nParameters\n----------\ntrain_transforms (List, optional): List of transforms for training. Defaults to None.\ntrain_mix_transforms (List, optional): List of mix transforms for training. Defaults to None.\ninference_transforms (List, optional): List of transforms for inference. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)",
			"API_3": "Trainer.train(gpus: str, project_name: str): Train the model with the specified configuration. Returns a dictionary containing information about the training.\n\n\nParameters\n----------\ngpus (str): GPU ids to use, separated by commas.\nproject_name (str): Project name to save the experiment.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.augmentations import Resize\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\n\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\n\ntrainer.set_dataset_config(\n    name='traffic_sign_config_example',\n    root_path='/root/traffic-sign',\n    train_image='images/train',\n    train_label='labels/train',\n    valid_image='images/valid',\n    valid_label='labels/valid',\n    id_mapping=['prohibitory', 'danger', 'mandatory', 'other'],)\n\n\ntrainer.set_model_config(model_name='YOLOX-S', img_size=512)\n\ntrainer.set_augmentation_config(\n    train_transforms=[Resize()],\n    inference_transforms=[Resize()],\n)\n\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n    epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n    scheduler=scheduler,)\n\ntraining_result = trainer.train(gpus='0, 1', project_name='project_sample')",
			"API_4": "Trainer.set_logging_config(project_id: Optional[str] = None, output_dir: str = './outputs', tensorboard: bool = True, csv: bool = False, image: bool = True, stdout: bool = True, save_optimizer_state: bool = True, validation_epoch: int = 10, save_checkpoint_epoch: Optional[int] = None): Set the logging configuration.\n\n\nParameters\n----------\nproject_id (str, optional): Project name to save the experiment. If None, it is set as {task}_{model} (e.g. segmentation_segformer).\noutput_dir (str, optional): Root directory for saving the experiment. Defaults to './outputs'.\ntensorboard (bool, optional): Whether to use the tensorboard. Defaults to True.\ncsv (bool, optional): Whether to save the result in csv format. Defaults to False.\nimage (bool, optional): Whether to save the validation results. It is ignored if the task is classification. Defaults to True.\nstdout (bool, optional): Whether to log the standard output. Defaults to True.\nsave_optimizer_state (bool, optional): Whether to save optimizer state with model checkpoint to resume training. Defaults to True.\nvalidation_epoch (int, optional): Validation frequency in total training process. Defaults to 10.\nsave_checkpoint_epoch (int, optional): Checkpoint saving frequency in total training process. Defaults to None.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\ntrainer.set_logging_config(validation_epoch=10, save_checkpoint_epoch=5)",
			"API_5": "Trainer.set_training_config(optimizer, scheduler, epochs: int = 3, batch_size: int = 8): Set the training configuration.\n\n\nParameters\n----------\noptimizer: The configuration of optimizer.\nscheduler: The configuration of learning rate scheduler.\nepochs (int, optional): The total number of epoch for training the model. Defaults to 3.\nbatch_size (int, optional): The number of samples in single batch input. Defaults to 8.\n\n\nExamples\n----------\nfrom netspresso import NetsPresso\nfrom netspresso.enums import Task\nfrom netspresso.trainer.optimizers import AdamW\nfrom netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp\n\nnetspresso = NetsPresso(email='YOUR_EMAIL', password='YOUR_PASSWORD')\ntrainer = netspresso.trainer(task=Task.OBJECT_DETECTION)\noptimizer = AdamW(lr=6e-3)\nscheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)\ntrainer.set_training_config(\n   epochs=40,\n    batch_size=16,\n    optimizer=optimizer,\n  scheduler=scheduler,\n)"
		},
		"annotation": {
			"answerable": false,
			"reason_for_unanswerable": "out_of_db"
		}
	}
}