{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages, model=\"gpt-3.5-turbo\", temperature=0.2):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt(replace, ambiguity check) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacing(query):\n",
    "    content = f'Replacing a name or noun with a generic pronoun in the question. \\n\\\n",
    "        Q: Where in England was Dame Judi Dench born? A: Where in England was she born? \\n\\\n",
    "        Q: {query} A: '\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9768a057334f8aa729b2f0987c1f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('trivia_qa', 'rc.wikipedia', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [data['question'] for data in dataset]\n",
    "partial_questions = questions[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:44<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "replaced_questions = [replacing(q) for q in tqdm(partial_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('replaced_questions.json', 'w') as f:\n",
    "    json.dump({f'q_{idx+1}':q for idx, q in enumerate(replaced_questions)}, f)\n",
    "\n",
    "with open('original_questions.json', 'w') as f:\n",
    "    json.dump({f'q_{idx+1}':q for idx, q in enumerate(partial_questions)}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "직접 검수 후 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('replaced_questions.json', 'r') as f:\n",
    "    replaces = json.load(f)\n",
    "\n",
    "with open('original_questions.json', 'r') as f:\n",
    "    orginals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 11, 14, 16, 19, 20, 22, 26, 29, 30, 31, 32, 33, 35, 37, 38, 39, 42, 43, 47, 48]\n"
     ]
    }
   ],
   "source": [
    "diff = []\n",
    "new_dataset = []\n",
    "\n",
    "for idx, (original, replaced) in enumerate(zip(orginals.values(), replaces.values())):\n",
    "    if original != replaced:\n",
    "        diff.append(idx)\n",
    "        data_dict = {'ambiguous_q':replaced, 'precise_q':original}\n",
    "        new_dataset.append(data_dict)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델별 분류 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ambiguity(query):\n",
    "    content = f'''Q: Who was the first woman to make a solo flight across this ocean?\n",
    "    This question is ambiguous: True\n",
    "    Q: Who was the first woman to make a solo flight across the Atlantic?\n",
    "    This question is ambiguous: False\n",
    "    Q: In which city were Rotary Clubs set up in 1905?\n",
    "    This question is ambiguous: False\n",
    "    Q: Who along with Philips developed the CD in the late 70s?\n",
    "    This question is ambiguous: False\n",
    "    Q: Where is the multinational corporation based?\n",
    "    This question is ambiguous: True\n",
    "    Q: {query}\n",
    "    This question is ambiguous: '''\n",
    "\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        temperature=0.2,\n",
    "        prompt=content\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].text=='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ambiguity2(query):\n",
    "    content = f'''Q: Who was the first woman to make a solo flight across this ocean?\n",
    "    This question is ambiguous: True\n",
    "    Q: Who was the first woman to make a solo flight across the Atlantic?\n",
    "    This question is ambiguous: False\n",
    "    Q: In which city were Rotary Clubs set up in 1905?\n",
    "    This question is ambiguous: False\n",
    "    Q: Who along with Philips developed the CD in the late 70s?\n",
    "    This question is ambiguous: False\n",
    "    Q: Where is the multinational corporation based?\n",
    "    This question is ambiguous: True\n",
    "    Q: {query}\n",
    "    This question is ambiguous: '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return get_response(messages) == 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ambiguity3(query):\n",
    "    content = f'''Q: Who was the first woman to make a solo flight across this ocean?\n",
    "    This question is ambiguous: True\n",
    "    Q: Who was the first woman to make a solo flight across the Atlantic?\n",
    "    This question is ambiguous: False\n",
    "    Q: In which city were Rotary Clubs set up in 1905?\n",
    "    This question is ambiguous: False\n",
    "    Q: Who along with Philips developed the CD in the late 70s?\n",
    "    This question is ambiguous: False\n",
    "    Q: Where is the multinational corporation based?\n",
    "    This question is ambiguous: True\n",
    "    Q: {query}\n",
    "    This question is ambiguous: '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return get_response(messages, model=\"gpt-3.5-turbo-16k\") == 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:18<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "replaces_check_result = [check_ambiguity(q) for q in tqdm(replaces.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "replaces_check_result2 = [check_ambiguity2(q) for q in tqdm(replaces.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:27<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "replaces_check_result3 = [check_ambiguity3(q) for q in tqdm(replaces.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1 if i in diff else 0 for i in range(50)]\n",
    "y_pred = [1 if val else 0 for val in replaces_check_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = [1 if val else 0 for val in replaces_check_result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = [1 if val else 0 for val in replaces_check_result3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-3.5-turbo-instruct\n",
      "Acc: 0.700, Pre: 0.680, Rec: 0.708, F1: 0.694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Model: gpt-3.5-turbo-instruct\")\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Acc: {accuracy:0.3f}, Pre: {precision:0.3f}, Rec: {recall:0.3f}, F1: {f1:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-3.5-turbo\n",
      "Acc: 0.760, Pre: 0.714, Rec: 0.833, F1: 0.769\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: gpt-3.5-turbo\")\n",
    "accuracy = accuracy_score(y_true, y_pred2)\n",
    "precision = precision_score(y_true, y_pred2)\n",
    "recall = recall_score(y_true, y_pred2)\n",
    "f1 = f1_score(y_true, y_pred2)\n",
    "\n",
    "print(f'Acc: {accuracy:0.3f}, Pre: {precision:0.3f}, Rec: {recall:0.3f}, F1: {f1:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-3.5-turbo-16k\n",
      "Acc: 0.700, Pre: 0.655, Rec: 0.792, F1: 0.717\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: gpt-3.5-turbo-16k\")\n",
    "accuracy = accuracy_score(y_true, y_pred3)\n",
    "precision = precision_score(y_true, y_pred3)\n",
    "recall = recall_score(y_true, y_pred3)\n",
    "f1 = f1_score(y_true, y_pred3)\n",
    "\n",
    "print(f'Acc: {accuracy:0.3f}, Pre: {precision:0.3f}, Rec: {recall:0.3f}, F1: {f1:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Evaluation Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ambiguous_q': 'Who was the next British Prime Minister after him?',\n",
       "  'precise_q': 'Who was the next British Prime Minister after Arthur Balfour?'},\n",
       " {'ambiguous_q': 'Who had a 70s No 1 hit with it?',\n",
       "  'precise_q': 'Who had a 70s No 1 hit with Kiss You All Over?'},\n",
       " {'ambiguous_q': 'What claimed her life?',\n",
       "  'precise_q': 'What claimed the life of singer Kathleen Ferrier?'},\n",
       " {'ambiguous_q': 'What was the name of his autobiography written in 1988?',\n",
       "  'precise_q': \"What was the name of Michael Jackson's autobiography written in 1988?\"},\n",
       " {'ambiguous_q': 'Who had an 80s No 1 hit with it?',\n",
       "  'precise_q': 'Who had an 80s No 1 hit with Hold On To The Nights?'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_clarify(query):\n",
    "    content = f\"\"\"This is a conversation between a user and a question-answering bot.\n",
    "    User: On what date did he land on the moon?\n",
    "    Bot: To answer this question, I need to ask the following clarifying question:\n",
    "    Who is he?\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    User: Which country on this continent has the largest population?\n",
    "    Bot: To answer this question, I need to ask the following clarifying question:\n",
    "    Which continent?\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    User: {query}\n",
    "    Bot: To answer this question, I need to ask the following clarifying question: \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    "    \n",
    "    return get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clarified_answer(pair):\n",
    "    added_question = question_to_clarify(pair['ambiguous_q'])\n",
    "    content=f'''This is a conversation between a user and a question-answering bot. The user wants to get an answer to the following question: “{pair['precise_q']}”\n",
    "    User: {pair['ambiguous_q']}\n",
    "    Bot: {added_question}\n",
    "    User: '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Your answer should be noun, name or nouns\"},\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    "    \n",
    "    return get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who had a 70s No 1 hit with it?\n",
      "Context: Who had a 70s No 1 hit with Kiss You All Over?\n",
      "Kiss You All Over\n"
     ]
    }
   ],
   "source": [
    "q_idx = 1\n",
    "print(new_dataset[q_idx]['ambiguous_q'])\n",
    "answer = get_clarified_answer(new_dataset[q_idx])\n",
    "print(f\"Context: {new_dataset[q_idx]['precise_q']}\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which country does it come from?\n",
      "Context: Which country does the airline TAAG come from?\n",
      "TAAG\n"
     ]
    }
   ],
   "source": [
    "q_idx = 20\n",
    "print(new_dataset[q_idx]['ambiguous_q'])\n",
    "answer = get_clarified_answer(new_dataset[q_idx])\n",
    "print(f\"Context: {new_dataset[q_idx]['precise_q']}\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_answer(ambiguous_q, clarifying_q, clarifying_a):\n",
    "    content=f'''User: {ambiguous_q}\n",
    "    Bot: {clarifying_q}\n",
    "    User: {clarifying_a}\n",
    "    Bot: '''\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": content}\n",
    "    ]\n",
    "\n",
    "    return get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_protocol(pair):\n",
    "    print(f\"Original Question: {pair['precise_q']}\\n\")\n",
    "    print(f\"User: {pair['ambiguous_q']}\")\n",
    "    clarifying_question = question_to_clarify(pair['ambiguous_q'])\n",
    "    print(f'Bot: {clarifying_question}')\n",
    "    clarifying_answer = get_clarified_answer(pair)\n",
    "    print(f'User: {clarifying_answer}')\n",
    "    final_answer = get_final_answer(pair['ambiguous_q'], clarifying_question, clarifying_answer)\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: In Greek mythology, who were Arges, Brontes and Steropes?\n",
      "\n",
      "User: In Greek mythology, who were they?\n",
      "Bot: Who are you referring to as \"they\" in Greek mythology?\n",
      "User: Arges, Brontes, and Steropes.\n",
      "Bot: Arges, Brontes, and Steropes were the Cyclopes in Greek mythology. They were giant, one-eyed beings who were skilled blacksmiths and craftsmen. They were known for forging Zeus' thunderbolts and other powerful weapons for the gods.\n"
     ]
    }
   ],
   "source": [
    "final_answer = automatic_protocol(new_dataset[14])\n",
    "print(f\"Bot: {final_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: How was the European Recovery Program in the 1940s more commonly known?\n",
      "\n",
      "User: How was it more commonly known?\n",
      "Bot: What is \"it\" referring to?\n",
      "User: The European Recovery Program in the 1940s.\n",
      "Bot: The European Recovery Program in the 1940s was more commonly known as the Marshall Plan.\n"
     ]
    }
   ],
   "source": [
    "final_answer = automatic_protocol(new_dataset[18])\n",
    "print(f\"Bot: {final_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: What was Truman Capote's last name before he was adopted by his stepfather?\n",
      "\n",
      "User: What was his last name before he was adopted by his stepfather?\n",
      "Bot: Who are you referring to?\n",
      "User: Truman Capote\n",
      "Bot: Truman Capote's last name before he was adopted by his stepfather was Streckfus.\n"
     ]
    }
   ],
   "source": [
    "final_answer = automatic_protocol(new_dataset[7])\n",
    "print(f\"Bot: {final_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
