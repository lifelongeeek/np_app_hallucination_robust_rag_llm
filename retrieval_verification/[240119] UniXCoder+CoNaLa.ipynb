{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unixcoder import UniXcoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UniXcoder(\"microsoft/unixcoder-base\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/datasets/load.py:1429: FutureWarning: The repository for neulab/conala contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/neulab/conala\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "conala = load_dataset('neulab/conala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 41067960,\n",
       " 'intent': 'How to convert a list of multiple integers into a single integer?',\n",
       " 'rewritten_intent': \"Concatenate elements of a list 'x' of multiple integers to a single integer\",\n",
       " 'snippet': 'sum(d * 10 ** i for i, d in enumerate(x[::-1]))'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conala['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Funtions\n",
    "\n",
    "def get_hit_rate(k, topk_list, n):\n",
    "    hits = sum([1 if topk < k else 0 for topk in topk_list])\n",
    "    return hits/n * 100\n",
    "\n",
    "def mean_reciprocal_rank(ranks):\n",
    "    reciprocal_ranks = 1.0 / ranks.float()\n",
    "    mrr = torch.mean(reciprocal_ranks)\n",
    "    return mrr.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, intent_tokens_ids, snippet_tokens_ids):\n",
    "        super().__init__()\n",
    "        self.intent_tokens_ids = intent_tokens_ids\n",
    "        self.snippet_tokens_ids = snippet_tokens_ids\n",
    "        self.len = len(intent_tokens_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'intent': torch.Tensor(self.intent_tokens_ids[index]),\n",
    "            'snippet': torch.Tensor(self.snippet_tokens_ids[index]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_intent_texts = [data['rewritten_intent'] for data in conala['train']]\n",
    "train_intent_texts = []\n",
    "train_snippet_texts = []\n",
    "\n",
    "for idx, text in enumerate(raw_train_intent_texts):\n",
    "    if text:\n",
    "        train_intent_texts.append(text)\n",
    "        train_snippet_texts.append(conala['train'][idx]['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_intent_tokens_ids = model.tokenize(train_intent_texts)\n",
    "train_snippet_tokens_ids = model.tokenize(train_snippet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dataset = TokenDataset(train_intent_tokens_ids, train_snippet_tokens_ids)\n",
    "token_dataloader = DataLoader(token_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2300/2300 [00:39<00:00, 57.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_intent_embeddings = []\n",
    "train_snippet_embeddings = []\n",
    "\n",
    "for batch in tqdm(token_dataloader):\n",
    "    inputs = batch['intent'].to(device).long()\n",
    "    outputs = batch['snippet'].to(device).long()\n",
    "    _, intent_embedding = model(inputs)\n",
    "    _, snippet_embedding = model(outputs)\n",
    "\n",
    "    train_intent_embeddings.append(intent_embedding.detach().cpu())\n",
    "    train_snippet_embeddings.append(snippet_embedding.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm_intent_embeddings = [torch.nn.functional.normalize(intent, p=2, dim=1) for intent in train_intent_embeddings]\n",
    "train_norm_snippet_embeddings = [torch.nn.functional.normalize(snippet, p=2, dim=1) for snippet in train_snippet_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snippet_emb_concat = torch.concat(train_norm_snippet_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2300/2300 [00:00<00:00, 3307.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_topk_list = []\n",
    "\n",
    "for idx, emb in enumerate(tqdm(train_norm_intent_embeddings)):\n",
    "    similarity = torch.matmul(train_snippet_emb_concat, emb.T).squeeze()\n",
    "    argsorted = torch.argsort(similarity, descending=True)\n",
    "    topk = (argsorted == idx).nonzero(as_tuple=True)[0].item()\n",
    "    train_topk_list.append(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10:\t88.91%\n",
      "Recall@50:\t95.87%\n",
      "Recall@100:\t97.39%\n",
      "Recall@200:\t98.65%\n",
      "MRR: 72.47%\n"
     ]
    }
   ],
   "source": [
    "n = len(train_topk_list)\n",
    "print(f'Recall@10:\\t{get_hit_rate(10, train_topk_list, n):0.2f}%')\n",
    "print(f'Recall@50:\\t{get_hit_rate(50, train_topk_list, n):0.2f}%')\n",
    "print(f'Recall@100:\\t{get_hit_rate(100, train_topk_list, n):0.2f}%')\n",
    "print(f'Recall@200:\\t{get_hit_rate(200, train_topk_list, n):0.2f}%')\n",
    "print(f'MRR: {mean_reciprocal_rank(torch.Tensor(train_topk_list)+1):0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_intent_texts = [data['rewritten_intent'] for data in conala['test']]\n",
    "test_intent_texts = []\n",
    "test_snippet_texts = []\n",
    "\n",
    "for idx, text in enumerate(raw_test_intent_texts):\n",
    "    if text:\n",
    "        test_intent_texts.append(text)\n",
    "        test_snippet_texts.append(conala['test'][idx]['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_intent_tokens_ids = model.tokenize(test_intent_texts)\n",
    "test_snippet_tokens_ids = model.tokenize(test_snippet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dataset = TokenDataset(test_intent_tokens_ids, test_snippet_tokens_ids)\n",
    "token_dataloader = DataLoader(token_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:09<00:00, 52.93it/s]\n"
     ]
    }
   ],
   "source": [
    "test_intent_embeddings = []\n",
    "test_snippet_embeddings = []\n",
    "\n",
    "for batch in tqdm(token_dataloader):\n",
    "    inputs = batch['intent'].to(device).long()\n",
    "    outputs = batch['snippet'].to(device).long()\n",
    "    _, intent_embedding = model(inputs)\n",
    "    _, snippet_embedding = model(outputs)\n",
    "\n",
    "    test_intent_embeddings.append(intent_embedding.detach().cpu())\n",
    "    test_snippet_embeddings.append(snippet_embedding.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_intent_embeddings = [torch.nn.functional.normalize(intent, p=2, dim=1) for intent in test_intent_embeddings]\n",
    "test_norm_snippet_embeddings = [torch.nn.functional.normalize(snippet, p=2, dim=1) for snippet in test_snippet_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_snippet_emb_concat = torch.concat(test_norm_snippet_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:00<00:00, 8526.53it/s]\n"
     ]
    }
   ],
   "source": [
    "test_topk_list = []\n",
    "\n",
    "for idx, emb in enumerate(tqdm(test_norm_intent_embeddings)):\n",
    "    similarity = torch.matmul(test_snippet_emb_concat, emb.T).squeeze()\n",
    "    argsorted = torch.argsort(similarity, descending=True)\n",
    "    topk = (argsorted == idx).nonzero(as_tuple=True)[0].item()\n",
    "    test_topk_list.append(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10:\t95.81%\n",
      "Recall@50:\t99.79%\n",
      "Recall@100:\t100.00%\n",
      "Recall@200:\t100.00%\n",
      "MRR: 79.63%\n"
     ]
    }
   ],
   "source": [
    "n = len(test_topk_list)\n",
    "print(f'Recall@10:\\t{get_hit_rate(10, test_topk_list, n):0.2f}%')\n",
    "print(f'Recall@50:\\t{get_hit_rate(50, test_topk_list, n):0.2f}%')\n",
    "print(f'Recall@100:\\t{get_hit_rate(100, test_topk_list, n):0.2f}%')\n",
    "print(f'Recall@200:\\t{get_hit_rate(200, test_topk_list, n):0.2f}%')\n",
    "print(f'MRR: {mean_reciprocal_rank(torch.Tensor(test_topk_list)+1):0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainset + Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_norm_intent_embeddings = train_norm_intent_embeddings + test_norm_intent_embeddings\n",
    "total_norm_snippet_embeddings = train_norm_snippet_embeddings + test_norm_snippet_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_snippet_emb_concat = torch.concat(total_norm_snippet_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2777/2777 [00:00<00:00, 3192.27it/s]\n"
     ]
    }
   ],
   "source": [
    "total_topk_list = []\n",
    "\n",
    "for idx, emb in enumerate(tqdm(total_norm_intent_embeddings)):\n",
    "    similarity = torch.matmul(total_snippet_emb_concat, emb.T).squeeze()\n",
    "    argsorted = torch.argsort(similarity, descending=True)\n",
    "    topk = (argsorted == idx).nonzero(as_tuple=True)[0].item()\n",
    "    total_topk_list.append(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10:\t87.94%\n",
      "Recall@50:\t95.14%\n",
      "Recall@100:\t97.23%\n",
      "Recall@200:\t98.38%\n",
      "MRR: 71.33%\n"
     ]
    }
   ],
   "source": [
    "n = len(total_topk_list)\n",
    "print(f'Recall@10:\\t{get_hit_rate(10, total_topk_list, n):0.2f}%')\n",
    "print(f'Recall@50:\\t{get_hit_rate(50, total_topk_list, n):0.2f}%')\n",
    "print(f'Recall@100:\\t{get_hit_rate(100, total_topk_list, n):0.2f}%')\n",
    "print(f'Recall@200:\\t{get_hit_rate(200, total_topk_list, n):0.2f}%')\n",
    "print(f'MRR: {mean_reciprocal_rank(torch.Tensor(total_topk_list)+1):0.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
